{
  "language": "Solidity",
  "sources": {
    "@openzeppelin/contracts/access/Ownable.sol": {
      "content": "// SPDX-License-Identifier: MIT\n// OpenZeppelin Contracts (last updated v4.9.0) (access/Ownable.sol)\n\npragma solidity ^0.8.0;\n\nimport \"../utils/Context.sol\";\n\n/**\n * @dev Contract module which provides a basic access control mechanism, where\n * there is an account (an owner) that can be granted exclusive access to\n * specific functions.\n *\n * By default, the owner account will be the one that deploys the contract. This\n * can later be changed with {transferOwnership}.\n *\n * This module is used through inheritance. It will make available the modifier\n * `onlyOwner`, which can be applied to your functions to restrict their use to\n * the owner.\n */\nabstract contract Ownable is Context {\n    address private _owner;\n\n    event OwnershipTransferred(address indexed previousOwner, address indexed newOwner);\n\n    /**\n     * @dev Initializes the contract setting the deployer as the initial owner.\n     */\n    constructor() {\n        _transferOwnership(_msgSender());\n    }\n\n    /**\n     * @dev Throws if called by any account other than the owner.\n     */\n    modifier onlyOwner() {\n        _checkOwner();\n        _;\n    }\n\n    /**\n     * @dev Returns the address of the current owner.\n     */\n    function owner() public view virtual returns (address) {\n        return _owner;\n    }\n\n    /**\n     * @dev Throws if the sender is not the owner.\n     */\n    function _checkOwner() internal view virtual {\n        require(owner() == _msgSender(), \"Ownable: caller is not the owner\");\n    }\n\n    /**\n     * @dev Leaves the contract without owner. It will not be possible to call\n     * `onlyOwner` functions. Can only be called by the current owner.\n     *\n     * NOTE: Renouncing ownership will leave the contract without an owner,\n     * thereby disabling any functionality that is only available to the owner.\n     */\n    function renounceOwnership() public virtual onlyOwner {\n        _transferOwnership(address(0));\n    }\n\n    /**\n     * @dev Transfers ownership of the contract to a new account (`newOwner`).\n     * Can only be called by the current owner.\n     */\n    function transferOwnership(address newOwner) public virtual onlyOwner {\n        require(newOwner != address(0), \"Ownable: new owner is the zero address\");\n        _transferOwnership(newOwner);\n    }\n\n    /**\n     * @dev Transfers ownership of the contract to a new account (`newOwner`).\n     * Internal function without access restriction.\n     */\n    function _transferOwnership(address newOwner) internal virtual {\n        address oldOwner = _owner;\n        _owner = newOwner;\n        emit OwnershipTransferred(oldOwner, newOwner);\n    }\n}\n"
    },
    "@openzeppelin/contracts/utils/Context.sol": {
      "content": "// SPDX-License-Identifier: MIT\n// OpenZeppelin Contracts v4.4.1 (utils/Context.sol)\n\npragma solidity ^0.8.0;\n\n/**\n * @dev Provides information about the current execution context, including the\n * sender of the transaction and its data. While these are generally available\n * via msg.sender and msg.data, they should not be accessed in such a direct\n * manner, since when dealing with meta-transactions the account sending and\n * paying for execution may not be the actual sender (as far as an application\n * is concerned).\n *\n * This contract is only required for intermediate, library-like contracts.\n */\nabstract contract Context {\n    function _msgSender() internal view virtual returns (address) {\n        return msg.sender;\n    }\n\n    function _msgData() internal view virtual returns (bytes calldata) {\n        return msg.data;\n    }\n}\n"
    },
    "contracts/AnomalyDetection.sol": {
      "content": "//SPDX-License-Identifier: MIT\npragma solidity >=0.8.0 <0.9.0;\n\nimport \"./DataLayer.sol\";\n\ncontract AnomalyDetection {\n\tDataLayer dataLayer;\n\n\tconstructor(DataLayer _dataLayer) {\n\t\tdataLayer = _dataLayer;\n\t}\n\n  // Get anomaly detection for any schema data\n  function getAnomalyDetection(bytes32 schemaName, uint256 threshold) public view returns(uint256[][] memory) {\n    uint256[][] memory analyticsData = dataLayer.getAnalyticsDataBySchemaName(schemaName);\n\n    uint256[] memory means = calculateMean(analyticsData);\n\n    uint256[] memory stdDevs = calculateStdDev(analyticsData, means);\n\n    uint256[][] memory predictions = detectAnomalies(analyticsData, means, stdDevs, threshold);\n\n    return predictions;\n  }\n\n  // Get anomaly detection for any offchain data\n  function getAnomalyDetectionOffChainData(uint256[][] memory analyticsData, uint256 threshold) public pure returns(uint256[][] memory) {\n\n    uint256[] memory means = calculateMean(analyticsData);\n\n    uint256[] memory stdDevs = calculateStdDev(analyticsData, means);\n\n    uint256[][] memory predictions = detectAnomalies(analyticsData, means, stdDevs, threshold);\n\n    return predictions;\n  }\n\n\n  function detectAnomalies(\n\t\tuint256[][] memory data,\n\t\tuint256[] memory means,\n\t\tuint256[] memory stddevs,\n\t\tuint256 threshold\n\t) internal pure returns (uint256[][] memory) {\n\t\tuint256[] memory anomalies = new uint256[](data.length);\n\t\tuint256 numColumns = data[1].length;\n\n\t\tuint256 idx = 0;\n\t\tfor (uint i = 1; i < data.length; i++) {\n\t\t\tif (isAnomalous(numColumns, data[i], means, stddevs, threshold)) {\n\t\t\t\tanomalies[idx] = i;\n\t\t\t\tidx += 1;\n\t\t\t}\n\t\t}\n\n    uint256[][] memory anomalousRows = new uint256[][](idx);\n    for (uint256 i = 0; i < idx; i++) {\n      anomalousRows[i] = data[anomalies[i]];\n    }\n\t\t\n    return anomalousRows;\n\t}\n\n\tfunction isAnomalous(\n\t\tuint256 numColumns,\n\t\tuint256[] memory values,\n\t\tuint256[] memory means,\n\t\tuint256[] memory stddevs,\n\t\tuint256 threshold\n\t) internal pure returns (bool) {\n\t\trequire(values.length == numColumns, \"Incorrect number of columns\");\n\t\tfor (uint j = 0; j < numColumns; j++) {\n\t\t\tuint diff = values[j] > means[j]\n\t\t\t\t? values[j] - means[j]\n\t\t\t\t: means[j] - values[j];\n\t\t\tif (diff * 100 > (threshold * stddevs[j])) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n\n\t\n\n\t/**\n\t * @dev Calculate mean of a matrix\n\t */\n\tfunction calculateMean(\n\t\tuint256[][] memory data\n\t) internal pure returns (uint256[] memory) {\n\t\tuint256 numColumns = data[1].length;\n\t\tuint256[] memory sums = new uint256[](numColumns);\n\t\tfor (uint i = 0; i < data.length; i++) {\n\t\t\tfor (uint j = 0; j < numColumns; j++) {\n\t\t\t\tsums[j] += data[i][j];\n\t\t\t}\n\t\t}\n\n\t\tuint256[] memory means = new uint256[](numColumns);\n\t\tfor (uint j = 0; j < numColumns; j++) {\n\t\t\tmeans[j] = sums[j] / data.length;\n\t\t}\n\n\t\treturn means;\n\t}\n\n\t/**\n\t * @dev Calculate standard deviation of a matrix\n\t */\n\tfunction calculateStdDev(\n\t\tuint256[][] memory data,\n\t\tuint256[] memory means\n\t) internal pure returns (uint256[] memory) {\n\t\tuint256 numColumns = data[1].length;\n\t\tuint[] memory sumSquares = new uint[](numColumns);\n\n\t\tfor (uint i = 0; i < data.length; i++) {\n\t\t\tfor (uint j = 0; j < numColumns; j++) {\n\t\t\t\tuint diff = data[i][j] > means[j]\n\t\t\t\t\t? data[i][j] - means[j]\n\t\t\t\t\t: means[j] - data[i][j];\n\t\t\t\tsumSquares[j] += diff * diff;\n\t\t\t}\n\t\t}\n\n\t\tuint256[] memory stddevs = new uint256[](numColumns);\n\t\tfor (uint j = 0; j < numColumns; j++) {\n\t\t\tstddevs[j] = sqrt(sumSquares[j] / data.length);\n\t\t}\n\n\t\treturn stddevs;\n\t}\n\n\t/**\n\t * @dev Returns the square root of a number.\n\t */\n\tfunction sqrt(uint256 x) internal pure returns (uint256) {\n\t\tuint256 z = (x + 1) / 2;\n\t\tuint256 y = x;\n\t\twhile (z < y) {\n\t\t\ty = z;\n\t\t\tz = ((x / z) + z) / 2;\n\t\t}\n\t\treturn y;\n\t}\n}\n"
    },
    "contracts/DataLayer.sol": {
      "content": "//SPDX-License-Identifier: MIT\npragma solidity >=0.8.0 <0.9.0;\n\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\n\ncontract DataLayer is Ownable {\n\tuint256[][] public userActivityMatrix;\n\tmapping(address => uint256) public addressToId;\n\tmapping(uint256 => address) public idToAddress;\n\tmapping(address => uint256) public consumerCredits;\n\tmapping(bytes32 => uint256) public schemaIndex;\n\tuint256 public latestIndex;\n\tuint256 public totalCategories;\n  uint256 public userRewardPerDatapoint;\n\n\tenum Category {\n\t\tGaming,\n\t\tMarketplace,\n\t\tDefi,\n\t\tDao,\n\t\tWeb3Social,\n\t\tIdentity,\n\t\tCertificates\n\t}\n\n  struct SchemaDetails {\n    bytes32 schemaName;\n\t\tbytes32[] columns;\n\t\tCategory schemaCategory;\n    uint256 totalRecords;\n  }\n\n\tstruct Analytics {\n\t\tbytes32 schemaName;\n\t\tbytes32[] columns;\n\t\tCategory schemaCategory;\n\t\tuint256[][] data;\n\t\tmapping(address => uint256) addressToId;\n\t\tmapping(uint256 => address) idToAddress;\n\t\tmapping(bytes32 => uint256) columnToIndex;\n\t}\n\n\tAnalytics[] public dappAnalytics;\n\n\tconstructor() Ownable() {\n\t\tuint256[] memory initialMatrix;\n\t\tuserActivityMatrix.push(initialMatrix);\n\t\tlatestIndex = 0;\n\t\ttotalCategories = 7;\n\t\tdappAnalytics.push();\n    userRewardPerDatapoint = 10000000000000000;\n\t}\n\n\tevent NewAnalytics(address user, address provider, uint256 category);\n\n\tfunction addUser(address userAddress) external {\n\t\t// get the total length of current activity matrix\n\t\tlatestIndex = latestIndex + 1;\n\t\tuint256[] memory initialMatrix;\n\t\tuserActivityMatrix.push(initialMatrix);\n\n\t\t// add the new user details\n\t\tfor (uint256 i = 0; i < totalCategories; i++) {\n\t\t\tuserActivityMatrix[latestIndex].push(0);\n\t\t}\n\n\t\t// add user id to address mapping\n\t\taddressToId[userAddress] = latestIndex;\n\t\tidToAddress[latestIndex] = userAddress;\n\t}\n\n\tfunction addSchema(\n\t\tbytes32 schemaName,\n\t\tbytes32[] calldata columns,\n\t\tCategory category\n\t) external {\n\t\t// Cannot have two schema with same name\n    require(schemaIndex[schemaName] == uint256(0), \"SCHEMA NAME EXISTS\");\n\n    // initializing schema with defaults\n\t\tAnalytics storage analytics = dappAnalytics.push();\n\t\tanalytics.schemaName = schemaName;\n\t\tanalytics.schemaCategory = category;\n\t\t\n    uint256[] memory initialUser;\n\t\tanalytics.data.push(initialUser);\n\t\t\n    for (uint256 i = 0; i < columns.length; i++) {\n\t\t\tanalytics.data[0].push(0);\n\t\t\tanalytics.columns.push(columns[i]);\n\t\t\tanalytics.columnToIndex[columns[i]] = i;\n\t\t}\n\n\t\t// adding to schema index map\n\t\tschemaIndex[schemaName] = dappAnalytics.length - 1;\n\t}\n\n\tfunction addAnalytics(\n\t\taddress payable userAddress,\n\t\tbytes32 schemaName,\n\t\tbytes32[] calldata columns,\n\t\tuint256[] calldata data\n\t) public payable {\n\t\trequire(schemaIndex[schemaName] != 0, \"SCHEMA NOT PRESENT\");\n\n\t\t// add user if not already present\n\t\tif (addressToId[userAddress] == 0) {\n\t\t\tthis.addUser(userAddress);\n\t\t}\n\n\t\t// retrieve storage instance\n\t\tAnalytics storage schemaAnalytics = dappAnalytics[\n\t\t\tschemaIndex[schemaName]\n\t\t];\n\n\t\t// push new user if not already present\n\t\tif (schemaAnalytics.addressToId[userAddress] == 0) {\n\t\t\tschemaAnalytics.data.push();\n\t\t\tfor (uint256 i = 0; i < schemaAnalytics.columns.length; i++) {\n\t\t\t\tschemaAnalytics.data[schemaAnalytics.data.length - 1].push(0);\n\t\t\t}\n\n\t\t\tschemaAnalytics.addressToId[userAddress] =\n\t\t\t\tschemaAnalytics.data.length -\n\t\t\t\t1;\n\t\t\tschemaAnalytics.idToAddress[\n\t\t\t\tschemaAnalytics.data.length - 1\n\t\t\t] = userAddress;\n\t\t}\n\n\t\t// add to the existing data\n\t\tfor (uint256 i = 0; i < columns.length; i++) {\n\t\t\tschemaAnalytics.data[schemaAnalytics.addressToId[userAddress]][\n\t\t\t\tschemaAnalytics.columnToIndex[columns[i]]\n\t\t\t] += data[i];\n\t\t}\n\n\t\tuserActivityMatrix[addressToId[userAddress]][\n\t\t\tuint256(schemaAnalytics.schemaCategory)\n\t\t] += 1;\n\n\t\t// rewarding the users for sharing data\n\t\tbool sent = userAddress.send(userRewardPerDatapoint);\n\t\trequire(sent, \"Failed to reward user\");\n\n\t\t// increasing credit limit for provider\n\t\tconsumerCredits[msg.sender] = consumerCredits[msg.sender] + 1;\n\n\t\temit NewAnalytics(\n\t\t\tuserAddress,\n\t\t\tmsg.sender,\n\t\t\tuint256(schemaAnalytics.schemaCategory)\n\t\t);\n\t}\n\n\tfunction updateAnalytics(\n\t\taddress payable userAddress,\n\t\tbytes32 schemaName,\n\t\tbytes32[] calldata columns,\n\t\tuint256[] calldata data\n\t) public payable {\n\t\t// add user if not already present\n\t\tif (addressToId[userAddress] == 0) {\n\t\t\tthis.addUser(userAddress);\n\t\t}\n\n\t\t// retrieve storage instance\n\t\tAnalytics storage schemaAnalytics = dappAnalytics[\n\t\t\tschemaIndex[schemaName]\n\t\t];\n\n\t\t// push new user if not already present\n\t\tif (schemaAnalytics.addressToId[userAddress] == 0) {\n\t\t\tschemaAnalytics.data.push();\n\t\t\tfor (uint256 i = 0; i < schemaAnalytics.columns.length; i++) {\n\t\t\t\tschemaAnalytics.data[schemaAnalytics.data.length - 1].push(0);\n\t\t\t}\n\n\t\t\tschemaAnalytics.addressToId[userAddress] =\n\t\t\t\tschemaAnalytics.data.length -\n\t\t\t\t1;\n\t\t\tschemaAnalytics.idToAddress[\n\t\t\t\tschemaAnalytics.data.length - 1\n\t\t\t] = userAddress;\n\t\t}\n\n\t\t// replace the existing user data with new one\n\t\tfor (uint256 i = 0; i < columns.length; i++) {\n\t\t\tschemaAnalytics.data[schemaAnalytics.addressToId[userAddress]][\n\t\t\t\tschemaAnalytics.columnToIndex[columns[i]]\n\t\t\t] = data[i];\n\t\t}\n\n\t\tuserActivityMatrix[addressToId[userAddress]][\n\t\t\tuint256(schemaAnalytics.schemaCategory)\n\t\t] += 1;\n\n\t\t// rewarding the users for sharing data\n\t\tbool sent = userAddress.send(userRewardPerDatapoint);\n\t\trequire(sent, \"Failed to reward user\");\n\n\t\t// increasing credit limit for provider\n\t\tconsumerCredits[msg.sender] = consumerCredits[msg.sender] + 1;\n\n\t\temit NewAnalytics(\n\t\t\tuserAddress,\n\t\t\tmsg.sender,\n\t\t\tuint256(schemaAnalytics.schemaCategory)\n\t\t);\n\t}\n\n  function updateUserReward(uint256 newReward) external onlyOwner {\n    userRewardPerDatapoint = newReward;\n  }\n\n\tfunction getUserActivityMatrix()\n\t\texternal\n\t\tview\n\t\treturns (uint256[][] memory)\n\t{\n\t\treturn userActivityMatrix;\n\t}\n\n  function getAllSchemas() external view returns (SchemaDetails[] memory) {\n    SchemaDetails[] memory schemaDetails = new SchemaDetails[](dappAnalytics.length - 1);\n    for (uint256 i = 1; i < dappAnalytics.length; i++) {\n      // bytes32[] memory schemaColumns = new bytes32[](dappAnalytics[i].columns.length);\n      SchemaDetails memory schemaDetail;\n      schemaDetail.schemaName = dappAnalytics[i].schemaName;\n      schemaDetail.columns = dappAnalytics[i].columns;\n      schemaDetail.schemaCategory = dappAnalytics[i].schemaCategory;\n      schemaDetail.totalRecords = dappAnalytics[i].data.length;\n      schemaDetails[i - 1] = schemaDetail;\n    }\n\n    return schemaDetails;\n  }\n\n\tfunction getAnalyticsDataBySchemaName(\n\t\tbytes32 schemaName\n\t) external view returns (uint256[][] memory) {\n\t\treturn dappAnalytics[schemaIndex[schemaName]].data;\n\t}\n\n\tfunction getColumnsOfSchema(\n\t\tbytes32 schemaName\n\t) external view returns (bytes32[] memory) {\n\t\treturn dappAnalytics[schemaIndex[schemaName]].columns;\n\t}\n\n  function getSchemaAddressToId(\n    bytes32 schemaName,\n    address userAddress\n  ) external view returns (uint256) {\n    return dappAnalytics[schemaIndex[schemaName]].addressToId[userAddress];\n  }\n\n  function getSchemaIdToAddress(\n    bytes32 schemaName,\n    uint256 userId\n  ) external view returns (address) {\n    return dappAnalytics[schemaIndex[schemaName]].idToAddress[userId];\n  }\n\n\treceive() external payable {}\n}\n"
    },
    "contracts/KNN.sol": {
      "content": "//SPDX-License-Identifier: MIT\npragma solidity >=0.8.0 <0.9.0;\n\nimport \"./DataLayer.sol\";\n\ncontract KNN {\n\n  DataLayer dataLayer;\n  uint256[][] public userActivityMatrix;\n  uint256 public totalCategories;\n\n  enum Distance {\n\t\tEuclidean,\n    Cosine\n\t}\n\n  struct similarityPair {\n\t\tuint256 index;\n\t\tuint256 similarity;\n\t}\n\n  constructor(DataLayer _dataLayer) {\n    dataLayer = _dataLayer;\n    userActivityMatrix = dataLayer.getUserActivityMatrix();\n    totalCategories = dataLayer.totalCategories();\n  }\n\n  // Get KNN of any schema row\n  function getKNN(bytes32 schemaName, uint256[] memory row, uint64 k, Distance distance) external view returns(uint256[][] memory) {\n    uint256[][] memory analyticsData = dataLayer.getAnalyticsDataBySchemaName(schemaName);\n\n    uint256[] memory similarityArray = computeSimilarityArray(analyticsData, row, distance);\n\n    uint256[][] memory predictions = getKNN(similarityArray, analyticsData, k);\n\n    return predictions;\n  }\n\n  // Get KNN of offchain data\n  function getKNNOffChainData(uint256[][] memory analyticsData, uint256[] memory row, uint64 k, Distance distance) external pure returns(uint256[][] memory) {\n\n    uint256[] memory similarityArray = computeSimilarityArray(analyticsData, row, distance);\n\n    uint256[][] memory predictions = getKNN(similarityArray, analyticsData, k);\n\n    return predictions;\n  }\n\n  function getRecommendedSimilarUsers(\n\t\taddress userAddress,\n\t\tuint64 k\n\t) external view returns (address[][] memory) {\n\t\tuint256[][] memory similarityMatrix = computeUserSimilarityMatrix();\n\n\t\taddress[][] memory recommendedFollowers = recommend(\n\t\t\tdataLayer.addressToId(userAddress),\n\t\t\tsimilarityMatrix,\n\t\t\tk\n\t\t);\n\n\t\treturn recommendedFollowers;\n\t}\n\n  // Function to compute similarity matrix\n\tfunction computeSimilarityArray(uint256[][] memory inputData, uint256[] memory test_row, Distance distance)\n\t\tinternal\n\t\tpure\n\t\treturns (uint256[] memory)\n\t{\n\t\tuint256 numRows = inputData.length;\n\t\tuint256[] memory similarityMatrix = new uint256[](numRows);\n\n\t\t// similarityMatrix.push();\n\t\tfor (uint256 i = 1; i < numRows; i++) {\n\t\t\tuint256[] memory row = inputData[i];\n      if (distance == Distance.Cosine) {\n        similarityMatrix[i] = cosineDistance(row, test_row);\n      } else {\n        similarityMatrix[i] = euclideanDistance(row, test_row);\n      }\n      \n\t\t}\n\n\t\treturn similarityMatrix;\n\t}\n\n\n\t// Function to compute user-user similarity matrix\n\tfunction computeUserSimilarityMatrix()\n\t\tinternal\n\t\tview\n\t\treturns (uint256[][] memory)\n\t{\n\t\tuint256 numUsers = userActivityMatrix.length;\n\t\tuint256[][] memory similarityMatrix = new uint256[][](numUsers);\n\n\t\t// similarityMatrix.push();\n\t\tfor (uint256 i = 1; i < numUsers; i++) {\n\t\t\tuint256[] memory row = new uint256[](numUsers);\n\t\t\tsimilarityMatrix[i] = row;\n\n\t\t\tfor (uint64 j = 1; j < numUsers; j++) {\n\t\t\t\tuint256[] memory user1 = userActivityMatrix[i];\n\t\t\t\tuint256[] memory user2 = userActivityMatrix[j];\n\t\t\t\tsimilarityMatrix[i][j] = cosineDistance(user1, user2);\n\t\t\t}\n\t\t}\n\n\t\treturn similarityMatrix;\n\t}\n\n  // Function to recommend similar users for a given user\n\tfunction getKNN(\n\t\tuint256[] memory similarityArray,\n    uint256[][] memory inputData,\n\t\tuint64 k\n\t) internal pure returns (uint256[][] memory) {\n\t\tsimilarityPair[] memory similarRows = new similarityPair[](\n\t\t\tsimilarityArray.length - 1\n\t\t);\n\t\tuint256 idx = 0;\n\n\t\t// Find k most similar users to the target user\n\t\tfor (uint256 j = 1; j < similarityArray.length; j++) {\t\n\t\t\tsimilarityPair memory row;\n\t\t\trow.index = j;\n\t\t\trow.similarity = similarityArray[j];\n\t\t\tsimilarRows[idx] = row;\n\t\t\tidx += 1;\n\t\t}\n\n\t\t// Sort similar users by descending similarity\n\t\tsimilarRows = bubbleSort(similarRows);\n\n\t\t// Recommend followers from the top k similar users\n\t\tuint256[][] memory recommendations = new uint256[][](\n\t\t\tk\n\t\t);\n\t\tfor (uint64 i = 0; i < k; i++) {\n      uint256[] memory row = new uint256[](inputData[similarRows[i].index].length);\n      recommendations[i] = row;\n      for (uint256 j = 0; j < inputData[similarRows[i].index].length; j++) {\n        recommendations[i][j] = inputData[similarRows[i].index][j];\n      }\n\t\t}\n\n\t\treturn recommendations;\n\t}\n\n\n\t// Function to recommend similar users for a given user\n\tfunction recommend(\n\t\tuint256 userIndex,\n\t\tuint256[][] memory similarityMatrix,\n\t\tuint64 k\n\t) public view returns (address[][] memory) {\n\t\tsimilarityPair[] memory similarUsers = new similarityPair[](\n\t\t\tsimilarityMatrix[userIndex].length - 1\n\t\t);\n\t\tuint256 idx = 0;\n\n\t\t// Find k most similar users to the target user\n\t\tfor (uint256 j = 1; j < similarityMatrix[userIndex].length; j++) {\n\t\t\tif (j != userIndex) {\n\t\t\t\tsimilarityPair memory row;\n\t\t\t\trow.index = j;\n\t\t\t\trow.similarity = similarityMatrix[userIndex][j];\n\t\t\t\tsimilarUsers[idx] = row;\n\t\t\t\tidx += 1;\n\t\t\t}\n\t\t}\n\n\t\t// Sort similar users by descending similarity\n\t\tsimilarUsers = bubbleSort(similarUsers);\n\n\t\t// Recommend followers from the top k similar users\n\t\taddress[][] memory recommendedFollowers = new address[][](\n\t\t\ttotalCategories\n\t\t);\n\t\tfor (uint64 i = 0; i < k; i++) {\n\t\t\tuint64 _idx = 0;\n\t\t\tfor (uint256 j = 0; j < totalCategories; j++) {\n\t\t\t\taddress[] memory followerRow = new address[](k);\n\t\t\t\trecommendedFollowers[j] = followerRow;\n\t\t\t\tif (userActivityMatrix[similarUsers[i].index][j] > 0) {\n\t\t\t\t\trecommendedFollowers[j][_idx] = dataLayer.idToAddress(\n\t\t\t\t\t\tsimilarUsers[i].index\n\t\t\t\t\t);\n\t\t\t\t\t_idx = _idx + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn recommendedFollowers;\n\t}\n\n  /**\n   * @dev Function to calculate cosine distance between two rows\n   */\n\tfunction cosineDistance(\n\t\tuint256[] memory row1,\n\t\tuint256[] memory row2\n\t) internal pure returns (uint256) {\n\t\tuint256 dotProduct = dot(row1, row2);\n\t\tuint256 normRow1 = sqrt(dot(row1, row1));\n\t\tuint256 normRow2 = sqrt(dot(row2, row2));\n\t\treturn ((dotProduct * 10000) / (normRow1 * normRow2));\n\t}\n\n  /**\n   * \n   * @dev Function to calculate euclidean distance between two rows\n   */\n  function euclideanDistance(\n    uint256[] memory row1,\n    uint256[] memory row2\n  ) internal pure returns (uint256) {\n    uint256 sum = 0;\n    for (uint256 i = 0; i < row1.length; i++) {\n      if(row1[i] > row2[i]) {\n        sum += (row1[i] - row2[i])**2;\n      } else {\n        sum += (row2[i] - row1[i])**2;\n      }\n      \n    }\n\n    return sqrt(sum);\n  } \n\n  \n\t/**\n\t * @dev Bubble sort.\n\t */\n\tfunction bubbleSort(\n\t\tsimilarityPair[] memory similarUsers\n\t) internal pure returns (similarityPair[] memory) {\n\t\tuint256 n = similarUsers.length;\n\t\tfor (uint256 i = 0; i < n - 1; i++) {\n\t\t\tfor (uint256 j = 0; j < n - i - 1; j++) {\n\t\t\t\tif (\n\t\t\t\t\tsimilarUsers[j].similarity > similarUsers[j + 1].similarity\n\t\t\t\t) {\n\t\t\t\t\t(similarUsers[j], similarUsers[j + 1]) = (\n\t\t\t\t\t\tsimilarUsers[j + 1],\n\t\t\t\t\t\tsimilarUsers[j]\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn similarUsers;\n\t}\n\n\t/**\n\t * @dev Returns the square root of a number.\n\t */\n\tfunction sqrt(uint256 x) internal pure returns (uint256) {\n\t\tuint256 z = (x + 1) / 2;\n\t\tuint256 y = x;\n\t\twhile (z < y) {\n\t\t\ty = z;\n\t\t\tz = ((x / z) + z) / 2;\n\t\t}\n\t\treturn y;\n\t}\n\n\t/**\n\t * @dev Returns the dot product of two vectors.\n\t */\n\tfunction dot(\n\t\tuint256[] memory x,\n\t\tuint256[] memory y\n\t) internal pure returns (uint256) {\n\t\trequire(x.length == y.length);\n\n\t\tuint256 output;\n\t\tfor (uint256 i = 0; i < x.length; i++) {\n\t\t\toutput = (x[i] * y[i]) + output;\n\t\t}\n\n\t\treturn output;\n\t}\n}"
    },
    "contracts/LinearRegression.sol": {
      "content": "//SPDX-License-Identifier: MIT\npragma solidity >=0.8.0 <0.9.0;\n\nimport \"./DataLayer.sol\";\n\ncontract LinearRegression {\n\tDataLayer dataLayer;\n\n\tint256 constant FIXED_POINT = 1e18; // Scaling factor for fixed-point arithmetic\n\n\tconstructor(DataLayer _dataLayer) {\n\t\tdataLayer = _dataLayer;\n\t}\n\n  // Get linear regression for onchain schema data\n\tfunction getLinearRegression(\n\t\tbytes32 schemaName,\n    uint256[] memory trainingColIndices,\n\t\tuint256 labelColIndex,\n    int256[][] memory testData,\n\t\tint256 learningRate,\n\t\tuint256 iterations,\n\t\tint256 bias\n\t) public view returns (int256[] memory) {\n\t\tuint256[][] memory analyticsData = dataLayer\n\t\t\t.getAnalyticsDataBySchemaName(schemaName);\n\n    int256[][] memory trainingData = new int256[][](analyticsData.length);\n\n\t\tint256[] memory labels = new int256[](analyticsData.length);\n\n\t\tfor (uint256 i = 1; i < analyticsData.length; i++) {\n      trainingData[i] = new int256[](trainingColIndices.length);\n\t\t\tlabels[i] = int256(analyticsData[i][labelColIndex]);\n\n      for (uint256 j = 0; j < trainingColIndices.length; j++) {\n        trainingData[i][j] = int256(analyticsData[i][trainingColIndices[j]]);\n      }\n\t\t}\n\n\t\tint256[] memory weights = fit(\n\t\t\ttrainingData,\n\t\t\tlabels,\n\t\t\tlearningRate,\n\t\t\titerations,\n\t\t\tbias\n\t\t);\n\n\t\tint256[] memory predictions = predict(testData, bias, weights);\n\n\t\treturn predictions;\n\t}\n\n  // Get linear regression for offchain data\n  function getLinearRegressionOffChain(\n\t\tint256[][] memory analyticsData,\n\t\tint256[] memory labels,\n\t\tint256[][] memory testData,\n\t\tint256 learningRate,\n\t\tuint256 iterations,\n\t\tint256 bias\n\t) public pure returns (int256[] memory) {\n\t\t\n\n\t\tint256[] memory weights = fit(\n\t\t\tanalyticsData,\n\t\t\tlabels,\n\t\t\tlearningRate,\n\t\t\titerations,\n\t\t\tbias\n\t\t);\n\n\t\tint256[] memory predictions = predict(testData, bias, weights);\n\n\t\treturn predictions;\n\t}\n\n\n\t/**\n\t * Fits the linear regression model to the training data\n\t * @param X - The training features.\n\t * @param y - The training labels.\n\t */\n\tfunction fit(\n\t\tint256[][] memory X,\n\t\tint256[] memory y,\n\t\tint256 learningRate,\n\t\tuint256 iterations,\n\t\tint256 bias\n\t) public pure returns (int256[] memory) {\n\t\trequire(\n\t\t\tX.length == y.length,\n\t\t\t\"Feature and label arrays must have the same length.\"\n\t\t);\n\n\t\t// uint256 m = X.length;\n\t\t// uint256 n = X[0].length;\n\n\t\t// Initialize weights\n\t\tint256[] memory weights = new int256[](X[0].length);\n\n\t\tfor (uint256 iter = 0; iter < iterations; iter++) {\n\t\t\tint256[] memory predictions = new int256[](X.length);\n\t\t\tint256[] memory dw = new int256[](X[0].length);\n\t\t\tint256 db = 0;\n\n\t\t\t// Compute predictions\n\t\t\tfor (uint256 i = 0; i < X.length; i++) {\n\t\t\t\tint256 linearModel = bias;\n\t\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\t\tlinearModel += (weights[j] * X[i][j]) / FIXED_POINT;\n\t\t\t\t}\n\t\t\t\tpredictions[i] = linearModel;\n\t\t\t}\n\n\t\t\t// Compute gradients\n\t\t\tfor (uint256 i = 0; i < X.length; i++) {\n\t\t\t\tint256 error = predictions[i] - y[i];\n\t\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\t\tdw[j] += (X[i][j] * error) / int256(X.length);\n\t\t\t\t}\n\t\t\t\tdb += error / int256(X.length);\n\t\t\t}\n\n\t\t\t// Update weights and bias\n\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\tweights[j] -= (learningRate * dw[j]) / FIXED_POINT;\n\t\t\t}\n\t\t\tbias -= (learningRate * db) / FIXED_POINT;\n\t\t}\n\n\t\treturn weights;\n\t}\n\n\t/**\n\t * Predicts the labels for the given input data\n\t * @param X - The input features.\n\t */\n\tfunction predict(\n\t\tint256[][] memory X,\n\t\tint256 bias,\n\t\tint256[] memory weights\n\t) public pure returns (int256[] memory) {\n\t\tuint256 m = X.length;\n\t\tint256[] memory predictions = new int256[](m);\n\n\t\tfor (uint256 i = 0; i < m; i++) {\n\t\t\tint256 linearModel = bias;\n\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\tlinearModel += (weights[j] * X[i][j]) / FIXED_POINT;\n\t\t\t}\n\t\t\tpredictions[i] = linearModel;\n\t\t}\n\n\t\treturn predictions;\n\t}\n}\n"
    },
    "contracts/LogisticRegression.sol": {
      "content": "//SPDX-License-Identifier: MIT\npragma solidity >=0.8.0 <0.9.0;\n\nimport \"./DataLayer.sol\";\n\ncontract LogisticRegression {\n\tDataLayer dataLayer;\n\n\tint256 constant FIXED_POINT = 1e18; // Scaling factor for fixed-point arithmetic\n\n\tconstructor(DataLayer _dataLayer) {\n\t\tdataLayer = _dataLayer;\n\t}\n\n  // Get linear regression for onchain schema data\n\tfunction getLogisticRegression(\n\t\tbytes32 schemaName,\n    uint256[] memory trainingColIndices,\n\t\tuint256 labelColIndex,\n    int256[][] memory testData,\n\t\tint256 learningRate,\n\t\tuint256 iterations,\n\t\tint256 bias\n\t) public view returns (int256[] memory) {\n\t\tuint256[][] memory analyticsData = dataLayer\n\t\t\t.getAnalyticsDataBySchemaName(schemaName);\n\n    int256[][] memory trainingData = new int256[][](analyticsData.length);\n\n\t\tint256[] memory labels = new int256[](analyticsData.length);\n\n\t\tfor (uint256 i = 1; i < analyticsData.length; i++) {\n      trainingData[i] = new int256[](trainingColIndices.length);\n\t\t\tlabels[i] = int256(analyticsData[i][labelColIndex]);\n\n      for (uint256 j = 0; j < trainingColIndices.length; j++) {\n        trainingData[i][j] = int256(analyticsData[i][trainingColIndices[j]]);\n      }\n\t\t}\n\n\t\tint256[] memory weights = fit(\n\t\t\ttrainingData,\n\t\t\tlabels,\n\t\t\tlearningRate,\n\t\t\titerations,\n\t\t\tbias\n\t\t);\n\n\t\tint256[] memory predictions = predict(testData, weights, bias);\n\n\t\treturn predictions;\n\t}\n\n\tfunction getLogisticRegressionOffChain(\n\t\tint256[][] memory analyticsData,\n\t\tint256[] memory labels,\n\t\tint256[][] memory testData,\n\t\tint256 learningRate,\n\t\tuint256 iterations,\n\t\tint256 bias\n\t) public pure returns (int256[] memory) {\n\t\tint256[] memory weights = fit(\n\t\t\tanalyticsData,\n\t\t\tlabels,\n\t\t\tlearningRate,\n\t\t\titerations,\n\t\t\tbias\n\t\t);\n\n\t\tint256[] memory predictions = predict(testData, weights, bias);\n\n\t\treturn predictions;\n\t}\n\n\t/**\n\t * Fits the logistic regression model to the training data\n\t * @param X - The training features.\n\t * @param y - The training labels.\n\t */\n\tfunction fit(\n\t\tint256[][] memory X,\n\t\tint256[] memory y,\n\t\tint256 learningRate,\n\t\tuint256 iterations,\n\t\tint256 bias\n\t) public pure returns (int256[] memory) {\n\t\trequire(\n\t\t\tX.length == y.length,\n\t\t\t\"Feature and label arrays must have the same length.\"\n\t\t);\n\n\t\t// Initialize weights\n\t\tint256[] memory weights = new int256[](X[0].length);\n\n\t\tfor (uint256 iter = 0; iter < iterations; iter++) {\n\t\t\tint256[] memory linearModel = new int256[](X.length);\n\t\t\tint256[] memory predictions = new int256[](X.length);\n\t\t\tint256[] memory dw = new int256[](X[0].length);\n\t\t\tint256 db = 0;\n\n\t\t\t// Compute linear model and predictions\n\t\t\tfor (uint256 i = 0; i < X.length; i++) {\n\t\t\t\tlinearModel[i] = bias;\n\t\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\t\tlinearModel[i] += (weights[j] * X[i][j]) / FIXED_POINT;\n\t\t\t\t}\n\t\t\t\tpredictions[i] = sigmoid(linearModel[i]);\n\t\t\t}\n\n\t\t\t// Compute gradients\n\t\t\tfor (uint256 i = 0; i < X.length; i++) {\n\t\t\t\tint256 error = predictions[i] - y[i];\n\t\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\t\tdw[j] += (X[i][j] * error) / FIXED_POINT;\n\t\t\t\t}\n\t\t\t\tdb += error;\n\t\t\t}\n\n\t\t\t// Update weights and bias\n\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\tweights[j] -= (learningRate * dw[j]) / int256(X.length);\n\t\t\t}\n\t\t\tbias -= (learningRate * db) / int256(X.length);\n\t\t}\n\n\t\treturn weights;\n\t}\n\n\t/**\n\t * Predicts the labels for the given input data\n\t * @param X - The input features.\n\t */\n\tfunction predict(\n\t\tint256[][] memory X,\n\t\tint256[] memory weights,\n\t\tint256 bias\n\t) public pure returns (int256[] memory) {\n\t\tuint256 m = X.length;\n\t\tint256[] memory predictions = new int256[](m);\n\n\t\tfor (uint256 i = 0; i < m; i++) {\n\t\t\tint256 linearModel = bias;\n\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\tlinearModel += (weights[j] * X[i][j]) / FIXED_POINT;\n\t\t\t}\n\t\t\tpredictions[i] = sigmoid(linearModel) >= (FIXED_POINT / int256(2))\n\t\t\t\t? int256(1)\n\t\t\t\t: int256(0);\n\t\t}\n\n\t\treturn predictions;\n\t}\n\n\t/**\n\t * Sigmoid function\n\t * @param z - The input value.\n\t */\n\tfunction sigmoid(int256 z) internal pure returns (int256) {\n\t\tint256 expValue = exp(z);\n\t\treturn expValue / (FIXED_POINT + expValue);\n\t}\n\n\t/**\n\t * Exponential function approximation\n\t * @param x - The input value.\n\t */\n\tfunction exp(int256 x) internal pure returns (int256) {\n\t\tint256 sum = FIXED_POINT;\n\t\tint256 term = FIXED_POINT;\n\t\tfor (int256 i = 1; i < 30; i++) {\n\t\t\tterm = (term * x) / int256(i * FIXED_POINT);\n\t\t\tsum += term;\n\t\t}\n\t\treturn sum;\n\t}\n}\n"
    }
  },
  "settings": {
    "optimizer": {
      "enabled": true,
      "runs": 200
    },
    "viaIR": true,
    "outputSelection": {
      "*": {
        "*": [
          "abi",
          "evm.bytecode",
          "evm.deployedBytecode",
          "evm.methodIdentifiers",
          "metadata",
          "devdoc",
          "userdoc",
          "storageLayout",
          "evm.gasEstimates"
        ],
        "": [
          "ast"
        ]
      }
    },
    "metadata": {
      "useLiteralContent": true
    }
  }
}