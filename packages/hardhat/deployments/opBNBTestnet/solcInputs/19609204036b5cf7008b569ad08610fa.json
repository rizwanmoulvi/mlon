{
  "language": "Solidity",
  "sources": {
    "@openzeppelin/contracts/access/Ownable.sol": {
      "content": "// SPDX-License-Identifier: MIT\n// OpenZeppelin Contracts (last updated v4.9.0) (access/Ownable.sol)\n\npragma solidity ^0.8.0;\n\nimport \"../utils/Context.sol\";\n\n/**\n * @dev Contract module which provides a basic access control mechanism, where\n * there is an account (an owner) that can be granted exclusive access to\n * specific functions.\n *\n * By default, the owner account will be the one that deploys the contract. This\n * can later be changed with {transferOwnership}.\n *\n * This module is used through inheritance. It will make available the modifier\n * `onlyOwner`, which can be applied to your functions to restrict their use to\n * the owner.\n */\nabstract contract Ownable is Context {\n    address private _owner;\n\n    event OwnershipTransferred(address indexed previousOwner, address indexed newOwner);\n\n    /**\n     * @dev Initializes the contract setting the deployer as the initial owner.\n     */\n    constructor() {\n        _transferOwnership(_msgSender());\n    }\n\n    /**\n     * @dev Throws if called by any account other than the owner.\n     */\n    modifier onlyOwner() {\n        _checkOwner();\n        _;\n    }\n\n    /**\n     * @dev Returns the address of the current owner.\n     */\n    function owner() public view virtual returns (address) {\n        return _owner;\n    }\n\n    /**\n     * @dev Throws if the sender is not the owner.\n     */\n    function _checkOwner() internal view virtual {\n        require(owner() == _msgSender(), \"Ownable: caller is not the owner\");\n    }\n\n    /**\n     * @dev Leaves the contract without owner. It will not be possible to call\n     * `onlyOwner` functions. Can only be called by the current owner.\n     *\n     * NOTE: Renouncing ownership will leave the contract without an owner,\n     * thereby disabling any functionality that is only available to the owner.\n     */\n    function renounceOwnership() public virtual onlyOwner {\n        _transferOwnership(address(0));\n    }\n\n    /**\n     * @dev Transfers ownership of the contract to a new account (`newOwner`).\n     * Can only be called by the current owner.\n     */\n    function transferOwnership(address newOwner) public virtual onlyOwner {\n        require(newOwner != address(0), \"Ownable: new owner is the zero address\");\n        _transferOwnership(newOwner);\n    }\n\n    /**\n     * @dev Transfers ownership of the contract to a new account (`newOwner`).\n     * Internal function without access restriction.\n     */\n    function _transferOwnership(address newOwner) internal virtual {\n        address oldOwner = _owner;\n        _owner = newOwner;\n        emit OwnershipTransferred(oldOwner, newOwner);\n    }\n}\n"
    },
    "@openzeppelin/contracts/utils/Context.sol": {
      "content": "// SPDX-License-Identifier: MIT\n// OpenZeppelin Contracts v4.4.1 (utils/Context.sol)\n\npragma solidity ^0.8.0;\n\n/**\n * @dev Provides information about the current execution context, including the\n * sender of the transaction and its data. While these are generally available\n * via msg.sender and msg.data, they should not be accessed in such a direct\n * manner, since when dealing with meta-transactions the account sending and\n * paying for execution may not be the actual sender (as far as an application\n * is concerned).\n *\n * This contract is only required for intermediate, library-like contracts.\n */\nabstract contract Context {\n    function _msgSender() internal view virtual returns (address) {\n        return msg.sender;\n    }\n\n    function _msgData() internal view virtual returns (bytes calldata) {\n        return msg.data;\n    }\n}\n"
    },
    "contracts/AnomalyDetection.sol": {
      "content": "//SPDX-License-Identifier: MIT\npragma solidity >=0.8.0 <0.9.0;\n\nimport \"./DataLayer.sol\";\n\ncontract AnomalyDetection {\n\tDataLayer dataLayer;\n\n\tconstructor(DataLayer _dataLayer) {\n\t\tdataLayer = _dataLayer;\n\t}\n\n  // Get anomaly detection for any schema data\n  function getAnomalyDetection(bytes32 schemaName, uint256 threshold) public view returns(uint256[][] memory) {\n    uint256[][] memory analyticsData = dataLayer.getAnalyticsDataBySchemaName(schemaName);\n\n    uint256[] memory means = calculateMean(analyticsData);\n\n    uint256[] memory stdDevs = calculateStdDev(analyticsData, means);\n\n    uint256[][] memory predictions = detectAnomalies(analyticsData, means, stdDevs, threshold);\n\n    return predictions;\n  }\n\n  // Get anomaly detection for any offchain data\n  function getAnomalyDetectionOffChainData(uint256[][] memory analyticsData, uint256 threshold) public pure returns(uint256[][] memory) {\n\n    uint256[] memory means = calculateMean(analyticsData);\n\n    uint256[] memory stdDevs = calculateStdDev(analyticsData, means);\n\n    uint256[][] memory predictions = detectAnomalies(analyticsData, means, stdDevs, threshold);\n\n    return predictions;\n  }\n\n\n  function detectAnomalies(\n\t\tuint256[][] memory data,\n\t\tuint256[] memory means,\n\t\tuint256[] memory stddevs,\n\t\tuint256 threshold\n\t) internal pure returns (uint256[][] memory) {\n\t\tuint256[] memory anomalies = new uint256[](data.length);\n\t\tuint256 numColumns = data[1].length;\n\n\t\tuint256 idx = 0;\n\t\tfor (uint i = 1; i < data.length; i++) {\n\t\t\tif (isAnomalous(numColumns, data[i], means, stddevs, threshold)) {\n\t\t\t\tanomalies[idx] = i;\n\t\t\t\tidx += 1;\n\t\t\t}\n\t\t}\n\n    uint256[][] memory anomalousRows = new uint256[][](idx);\n    for (uint256 i = 0; i < idx; i++) {\n      anomalousRows[i] = data[anomalies[i]];\n    }\n\t\t\n    return anomalousRows;\n\t}\n\n\tfunction isAnomalous(\n\t\tuint256 numColumns,\n\t\tuint256[] memory values,\n\t\tuint256[] memory means,\n\t\tuint256[] memory stddevs,\n\t\tuint256 threshold\n\t) internal pure returns (bool) {\n\t\trequire(values.length == numColumns, \"Incorrect number of columns\");\n\t\tfor (uint j = 0; j < numColumns; j++) {\n\t\t\tuint diff = values[j] > means[j]\n\t\t\t\t? values[j] - means[j]\n\t\t\t\t: means[j] - values[j];\n\t\t\tif (diff * 100 > (threshold * stddevs[j])) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n\n\t\n\n\t/**\n\t * @dev Calculate mean of a matrix\n\t */\n\tfunction calculateMean(\n\t\tuint256[][] memory data\n\t) internal pure returns (uint256[] memory) {\n\t\tuint256 numColumns = data[1].length;\n\t\tuint256[] memory sums = new uint256[](numColumns);\n\t\tfor (uint i = 0; i < data.length; i++) {\n\t\t\tfor (uint j = 0; j < numColumns; j++) {\n\t\t\t\tsums[j] += data[i][j];\n\t\t\t}\n\t\t}\n\n\t\tuint256[] memory means = new uint256[](numColumns);\n\t\tfor (uint j = 0; j < numColumns; j++) {\n\t\t\tmeans[j] = sums[j] / data.length;\n\t\t}\n\n\t\treturn means;\n\t}\n\n\t/**\n\t * @dev Calculate standard deviation of a matrix\n\t */\n\tfunction calculateStdDev(\n\t\tuint256[][] memory data,\n\t\tuint256[] memory means\n\t) internal pure returns (uint256[] memory) {\n\t\tuint256 numColumns = data[1].length;\n\t\tuint[] memory sumSquares = new uint[](numColumns);\n\n\t\tfor (uint i = 0; i < data.length; i++) {\n\t\t\tfor (uint j = 0; j < numColumns; j++) {\n\t\t\t\tuint diff = data[i][j] > means[j]\n\t\t\t\t\t? data[i][j] - means[j]\n\t\t\t\t\t: means[j] - data[i][j];\n\t\t\t\tsumSquares[j] += diff * diff;\n\t\t\t}\n\t\t}\n\n\t\tuint256[] memory stddevs = new uint256[](numColumns);\n\t\tfor (uint j = 0; j < numColumns; j++) {\n\t\t\tstddevs[j] = sqrt(sumSquares[j] / data.length);\n\t\t}\n\n\t\treturn stddevs;\n\t}\n\n\t/**\n\t * @dev Returns the square root of a number.\n\t */\n\tfunction sqrt(uint256 x) internal pure returns (uint256) {\n\t\tuint256 z = (x + 1) / 2;\n\t\tuint256 y = x;\n\t\twhile (z < y) {\n\t\t\ty = z;\n\t\t\tz = ((x / z) + z) / 2;\n\t\t}\n\t\treturn y;\n\t}\n}\n"
    },
    "contracts/DataLayer.sol": {
      "content": "//SPDX-License-Identifier: MIT\npragma solidity >=0.8.0 <0.9.0;\n\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\n\ncontract DataLayer is Ownable {\n\n    uint256[][] public userActivityMatrix;\n    mapping(address => uint256) public addressToId;\n    mapping(uint256 => address) public idToAddress;\n    mapping(address => uint256) public consumerCredits;\n    mapping(bytes32 => uint256) public schemaIndex;\n    uint256 public latestIndex;\n    uint256 public totalCategories;\n\n    enum Category {\n        Gaming,\n        Marketplace,\n        Defi,\n        Dao,\n        Web3Social,\n        Identity,\n        Certificates\n    }\n\n    struct SchemaDetails {\n        bytes32 schemaName;\n        bytes32[] columns;\n        Category schemaCategory;\n        uint256 totalRecords;\n    }\n\n    struct Analytics {\n        bytes32 schemaName;\n        bytes32[] columns;\n        Category schemaCategory;\n        uint256[][] data;\n        mapping(address => uint256) addressToId;\n        mapping(uint256 => address) idToAddress;\n        mapping(bytes32 => uint256) columnToIndex;\n    }\n\n    Analytics[] public dappAnalytics;\n\n    constructor() Ownable() {\n        uint256[] memory initialMatrix;\n        userActivityMatrix.push(initialMatrix);\n        latestIndex = 0;\n        totalCategories = 7;\n        dappAnalytics.push();\n    }\n\n    event NewAnalytics(address user, address provider, uint256 category);\n\n    function addUser(address userAddress) external {\n        latestIndex = latestIndex + 1;\n        uint256[] memory initialMatrix;\n        userActivityMatrix.push(initialMatrix);\n\n        for (uint256 i = 0; i < totalCategories; i++) {\n            userActivityMatrix[latestIndex].push(0);\n        }\n\n        addressToId[userAddress] = latestIndex;\n        idToAddress[latestIndex] = userAddress;\n    }\n\n    function addSchema(\n        bytes32 schemaName,\n        bytes32[] calldata columns,\n        Category category\n    ) external {\n        require(schemaIndex[schemaName] == uint256(0), \"SCHEMA NAME EXISTS\");\n\n        Analytics storage analytics = dappAnalytics.push();\n        analytics.schemaName = schemaName;\n        analytics.schemaCategory = category;\n\n        uint256[] memory initialUser;\n        analytics.data.push(initialUser);\n\n        for (uint256 i = 0; i < columns.length; i++) {\n            analytics.data[0].push(0);\n            analytics.columns.push(columns[i]);\n            analytics.columnToIndex[columns[i]] = i;\n        }\n\n        schemaIndex[schemaName] = dappAnalytics.length - 1;\n    }\n\n    function addAnalytics(\n        address userAddress,\n        bytes32 schemaName,\n        bytes32[] calldata columns,\n        uint256[] calldata data\n    ) public {\n        require(schemaIndex[schemaName] != 0, \"SCHEMA NOT PRESENT\");\n\n        if (addressToId[userAddress] == 0) {\n            this.addUser(userAddress);\n        }\n\n        Analytics storage schemaAnalytics = dappAnalytics[\n            schemaIndex[schemaName]\n        ];\n\n        if (schemaAnalytics.addressToId[userAddress] == 0) {\n            schemaAnalytics.data.push();\n            for (uint256 i = 0; i < schemaAnalytics.columns.length; i++) {\n                schemaAnalytics.data[schemaAnalytics.data.length - 1].push(0);\n            }\n\n            schemaAnalytics.addressToId[userAddress] =\n                schemaAnalytics.data.length - 1;\n            schemaAnalytics.idToAddress[\n                schemaAnalytics.data.length - 1\n            ] = userAddress;\n        }\n\n        for (uint256 i = 0; i < columns.length; i++) {\n            schemaAnalytics.data[schemaAnalytics.addressToId[userAddress]][\n                schemaAnalytics.columnToIndex[columns[i]]\n            ] += data[i];\n        }\n\n        userActivityMatrix[addressToId[userAddress]][\n            uint256(schemaAnalytics.schemaCategory)\n        ] += 1;\n\n        consumerCredits[msg.sender] = consumerCredits[msg.sender] + 1;\n\n        emit NewAnalytics(\n            userAddress,\n            msg.sender,\n            uint256(schemaAnalytics.schemaCategory)\n        );\n    }\n\n    function updateAnalytics(\n        address userAddress,\n        bytes32 schemaName,\n        bytes32[] calldata columns,\n        uint256[] calldata data\n    ) public {\n        if (addressToId[userAddress] == 0) {\n            this.addUser(userAddress);\n        }\n\n        Analytics storage schemaAnalytics = dappAnalytics[\n            schemaIndex[schemaName]\n        ];\n\n        if (schemaAnalytics.addressToId[userAddress] == 0) {\n            schemaAnalytics.data.push();\n            for (uint256 i = 0; i < schemaAnalytics.columns.length; i++) {\n                schemaAnalytics.data[schemaAnalytics.data.length - 1].push(0);\n            }\n\n            schemaAnalytics.addressToId[userAddress] =\n                schemaAnalytics.data.length - 1;\n            schemaAnalytics.idToAddress[\n                schemaAnalytics.data.length - 1\n            ] = userAddress;\n        }\n\n        for (uint256 i = 0; i < columns.length; i++) {\n            schemaAnalytics.data[schemaAnalytics.addressToId[userAddress]][\n                schemaAnalytics.columnToIndex[columns[i]]\n            ] = data[i];\n        }\n\n        userActivityMatrix[addressToId[userAddress]][\n            uint256(schemaAnalytics.schemaCategory)\n        ] += 1;\n\n        consumerCredits[msg.sender] = consumerCredits[msg.sender] + 1;\n\n        emit NewAnalytics(\n            userAddress,\n            msg.sender,\n            uint256(schemaAnalytics.schemaCategory)\n        );\n    }\n\n    function getUserActivityMatrix()\n        external\n        view\n        returns (uint256[][] memory)\n    {\n        return userActivityMatrix;\n    }\n\n    function getAllSchemas() external view returns (SchemaDetails[] memory) {\n        SchemaDetails[] memory schemaDetails = new SchemaDetails[](dappAnalytics.length - 1);\n        for (uint256 i = 1; i < dappAnalytics.length; i++) {\n            SchemaDetails memory schemaDetail;\n            schemaDetail.schemaName = dappAnalytics[i].schemaName;\n            schemaDetail.columns = dappAnalytics[i].columns;\n            schemaDetail.schemaCategory = dappAnalytics[i].schemaCategory;\n            schemaDetail.totalRecords = dappAnalytics[i].data.length;\n            schemaDetails[i - 1] = schemaDetail;\n        }\n\n        return schemaDetails;\n    }\n\n    function getAnalyticsDataBySchemaName(\n        bytes32 schemaName\n    ) external view returns (uint256[][] memory) {\n        return dappAnalytics[schemaIndex[schemaName]].data;\n    }\n\n    function getColumnsOfSchema(\n        bytes32 schemaName\n    ) external view returns (bytes32[] memory) {\n        return dappAnalytics[schemaIndex[schemaName]].columns;\n    }\n\n    function getSchemaAddressToId(\n        bytes32 schemaName,\n        address userAddress\n    ) external view returns (uint256) {\n        return dappAnalytics[schemaIndex[schemaName]].addressToId[userAddress];\n    }\n\n    function getSchemaIdToAddress(\n        bytes32 schemaName,\n        uint256 userId\n    ) external view returns (address) {\n        return dappAnalytics[schemaIndex[schemaName]].idToAddress[userId];\n    }\n\n}\n"
    },
    "contracts/KNN.sol": {
      "content": "//SPDX-License-Identifier: MIT\npragma solidity >=0.8.0 <0.9.0;\n\nimport \"./DataLayer.sol\";\n\ncontract KNN {\n\n  DataLayer dataLayer;\n  uint256[][] public userActivityMatrix;\n  uint256 public totalCategories;\n\n  enum Distance {\n\t\tEuclidean,\n    Cosine\n\t}\n\n  struct similarityPair {\n\t\tuint256 index;\n\t\tuint256 similarity;\n\t}\n\n  constructor(DataLayer _dataLayer) {\n    dataLayer = _dataLayer;\n    userActivityMatrix = dataLayer.getUserActivityMatrix();\n    totalCategories = dataLayer.totalCategories();\n  }\n\n  // Get KNN of any schema row\n  function getKNN(bytes32 schemaName, uint256[] memory row, uint64 k, Distance distance) external view returns(uint256[][] memory) {\n    uint256[][] memory analyticsData = dataLayer.getAnalyticsDataBySchemaName(schemaName);\n\n    uint256[] memory similarityArray = computeSimilarityArray(analyticsData, row, distance);\n\n    uint256[][] memory predictions = getKNN(similarityArray, analyticsData, k);\n\n    return predictions;\n  }\n\n  // Get KNN of offchain data\n  function getKNNOffChainData(uint256[][] memory analyticsData, uint256[] memory row, uint64 k, Distance distance) external pure returns(uint256[][] memory) {\n\n    uint256[] memory similarityArray = computeSimilarityArray(analyticsData, row, distance);\n\n    uint256[][] memory predictions = getKNN(similarityArray, analyticsData, k);\n\n    return predictions;\n  }\n\n  function getRecommendedSimilarUsers(\n\t\taddress userAddress,\n\t\tuint64 k\n\t) external view returns (address[][] memory) {\n\t\tuint256[][] memory similarityMatrix = computeUserSimilarityMatrix();\n\n\t\taddress[][] memory recommendedFollowers = recommend(\n\t\t\tdataLayer.addressToId(userAddress),\n\t\t\tsimilarityMatrix,\n\t\t\tk\n\t\t);\n\n\t\treturn recommendedFollowers;\n\t}\n\n  // Function to compute similarity matrix\n\tfunction computeSimilarityArray(uint256[][] memory inputData, uint256[] memory test_row, Distance distance)\n\t\tinternal\n\t\tpure\n\t\treturns (uint256[] memory)\n\t{\n\t\tuint256 numRows = inputData.length;\n\t\tuint256[] memory similarityMatrix = new uint256[](numRows);\n\n\t\t// similarityMatrix.push();\n\t\tfor (uint256 i = 1; i < numRows; i++) {\n\t\t\tuint256[] memory row = inputData[i];\n      if (distance == Distance.Cosine) {\n        similarityMatrix[i] = cosineDistance(row, test_row);\n      } else {\n        similarityMatrix[i] = euclideanDistance(row, test_row);\n      }\n      \n\t\t}\n\n\t\treturn similarityMatrix;\n\t}\n\n\n\t// Function to compute user-user similarity matrix\n\tfunction computeUserSimilarityMatrix()\n\t\tinternal\n\t\tview\n\t\treturns (uint256[][] memory)\n\t{\n\t\tuint256 numUsers = userActivityMatrix.length;\n\t\tuint256[][] memory similarityMatrix = new uint256[][](numUsers);\n\n\t\t// similarityMatrix.push();\n\t\tfor (uint256 i = 1; i < numUsers; i++) {\n\t\t\tuint256[] memory row = new uint256[](numUsers);\n\t\t\tsimilarityMatrix[i] = row;\n\n\t\t\tfor (uint64 j = 1; j < numUsers; j++) {\n\t\t\t\tuint256[] memory user1 = userActivityMatrix[i];\n\t\t\t\tuint256[] memory user2 = userActivityMatrix[j];\n\t\t\t\tsimilarityMatrix[i][j] = cosineDistance(user1, user2);\n\t\t\t}\n\t\t}\n\n\t\treturn similarityMatrix;\n\t}\n\n  // Function to recommend similar users for a given user\n\tfunction getKNN(\n\t\tuint256[] memory similarityArray,\n    uint256[][] memory inputData,\n\t\tuint64 k\n\t) internal pure returns (uint256[][] memory) {\n\t\tsimilarityPair[] memory similarRows = new similarityPair[](\n\t\t\tsimilarityArray.length - 1\n\t\t);\n\t\tuint256 idx = 0;\n\n\t\t// Find k most similar users to the target user\n\t\tfor (uint256 j = 1; j < similarityArray.length; j++) {\t\n\t\t\tsimilarityPair memory row;\n\t\t\trow.index = j;\n\t\t\trow.similarity = similarityArray[j];\n\t\t\tsimilarRows[idx] = row;\n\t\t\tidx += 1;\n\t\t}\n\n\t\t// Sort similar users by descending similarity\n\t\tsimilarRows = bubbleSort(similarRows);\n\n\t\t// Recommend followers from the top k similar users\n\t\tuint256[][] memory recommendations = new uint256[][](\n\t\t\tk\n\t\t);\n\t\tfor (uint64 i = 0; i < k; i++) {\n      uint256[] memory row = new uint256[](inputData[similarRows[i].index].length);\n      recommendations[i] = row;\n      for (uint256 j = 0; j < inputData[similarRows[i].index].length; j++) {\n        recommendations[i][j] = inputData[similarRows[i].index][j];\n      }\n\t\t}\n\n\t\treturn recommendations;\n\t}\n\n\n\t// Function to recommend similar users for a given user\n\tfunction recommend(\n\t\tuint256 userIndex,\n\t\tuint256[][] memory similarityMatrix,\n\t\tuint64 k\n\t) public view returns (address[][] memory) {\n\t\tsimilarityPair[] memory similarUsers = new similarityPair[](\n\t\t\tsimilarityMatrix[userIndex].length - 1\n\t\t);\n\t\tuint256 idx = 0;\n\n\t\t// Find k most similar users to the target user\n\t\tfor (uint256 j = 1; j < similarityMatrix[userIndex].length; j++) {\n\t\t\tif (j != userIndex) {\n\t\t\t\tsimilarityPair memory row;\n\t\t\t\trow.index = j;\n\t\t\t\trow.similarity = similarityMatrix[userIndex][j];\n\t\t\t\tsimilarUsers[idx] = row;\n\t\t\t\tidx += 1;\n\t\t\t}\n\t\t}\n\n\t\t// Sort similar users by descending similarity\n\t\tsimilarUsers = bubbleSort(similarUsers);\n\n\t\t// Recommend followers from the top k similar users\n\t\taddress[][] memory recommendedFollowers = new address[][](\n\t\t\ttotalCategories\n\t\t);\n\t\tfor (uint64 i = 0; i < k; i++) {\n\t\t\tuint64 _idx = 0;\n\t\t\tfor (uint256 j = 0; j < totalCategories; j++) {\n\t\t\t\taddress[] memory followerRow = new address[](k);\n\t\t\t\trecommendedFollowers[j] = followerRow;\n\t\t\t\tif (userActivityMatrix[similarUsers[i].index][j] > 0) {\n\t\t\t\t\trecommendedFollowers[j][_idx] = dataLayer.idToAddress(\n\t\t\t\t\t\tsimilarUsers[i].index\n\t\t\t\t\t);\n\t\t\t\t\t_idx = _idx + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn recommendedFollowers;\n\t}\n\n  /**\n   * @dev Function to calculate cosine distance between two rows\n   */\n\tfunction cosineDistance(\n\t\tuint256[] memory row1,\n\t\tuint256[] memory row2\n\t) internal pure returns (uint256) {\n\t\tuint256 dotProduct = dot(row1, row2);\n\t\tuint256 normRow1 = sqrt(dot(row1, row1));\n\t\tuint256 normRow2 = sqrt(dot(row2, row2));\n\t\treturn ((dotProduct * 10000) / (normRow1 * normRow2));\n\t}\n\n  /**\n   * \n   * @dev Function to calculate euclidean distance between two rows\n   */\n  function euclideanDistance(\n    uint256[] memory row1,\n    uint256[] memory row2\n  ) internal pure returns (uint256) {\n    uint256 sum = 0;\n    for (uint256 i = 0; i < row1.length; i++) {\n      if(row1[i] > row2[i]) {\n        sum += (row1[i] - row2[i])**2;\n      } else {\n        sum += (row2[i] - row1[i])**2;\n      }\n      \n    }\n\n    return sqrt(sum);\n  } \n\n  \n\t/**\n\t * @dev Bubble sort.\n\t */\n\tfunction bubbleSort(\n\t\tsimilarityPair[] memory similarUsers\n\t) internal pure returns (similarityPair[] memory) {\n\t\tuint256 n = similarUsers.length;\n\t\tfor (uint256 i = 0; i < n - 1; i++) {\n\t\t\tfor (uint256 j = 0; j < n - i - 1; j++) {\n\t\t\t\tif (\n\t\t\t\t\tsimilarUsers[j].similarity > similarUsers[j + 1].similarity\n\t\t\t\t) {\n\t\t\t\t\t(similarUsers[j], similarUsers[j + 1]) = (\n\t\t\t\t\t\tsimilarUsers[j + 1],\n\t\t\t\t\t\tsimilarUsers[j]\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn similarUsers;\n\t}\n\n\t/**\n\t * @dev Returns the square root of a number.\n\t */\n\tfunction sqrt(uint256 x) internal pure returns (uint256) {\n\t\tuint256 z = (x + 1) / 2;\n\t\tuint256 y = x;\n\t\twhile (z < y) {\n\t\t\ty = z;\n\t\t\tz = ((x / z) + z) / 2;\n\t\t}\n\t\treturn y;\n\t}\n\n\t/**\n\t * @dev Returns the dot product of two vectors.\n\t */\n\tfunction dot(\n\t\tuint256[] memory x,\n\t\tuint256[] memory y\n\t) internal pure returns (uint256) {\n\t\trequire(x.length == y.length);\n\n\t\tuint256 output;\n\t\tfor (uint256 i = 0; i < x.length; i++) {\n\t\t\toutput = (x[i] * y[i]) + output;\n\t\t}\n\n\t\treturn output;\n\t}\n}"
    },
    "contracts/LinearRegression.sol": {
      "content": "//SPDX-License-Identifier: MIT\npragma solidity >=0.8.0 <0.9.0;\n\nimport \"./DataLayer.sol\";\n\ncontract LinearRegression {\n\tDataLayer dataLayer;\n\n\tint256 constant FIXED_POINT = 1e9; // Scaling factor for fixed-point arithmetic\n\n\tconstructor(DataLayer _dataLayer) {\n\t\tdataLayer = _dataLayer;\n\t}\n\n  // Get linear regression for onchain schema data\n\tfunction getLinearRegression(\n\t\tbytes32 schemaName,\n    uint256[] memory trainingColIndices,\n\t\tuint256 labelColIndex,\n    int256[][] memory testData,\n\t\tint256 learningRate,\n\t\tuint256 iterations,\n\t\tint256 bias\n\t) public view returns (int256[] memory) {\n\t\tuint256[][] memory analyticsData = dataLayer\n\t\t\t.getAnalyticsDataBySchemaName(schemaName);\n\n    int256[][] memory trainingData = new int256[][](analyticsData.length);\n\n\t\tint256[] memory labels = new int256[](analyticsData.length);\n\n\t\tfor (uint256 i = 1; i < analyticsData.length; i++) {\n      trainingData[i] = new int256[](trainingColIndices.length);\n\t\t\tlabels[i] = int256(analyticsData[i][labelColIndex]) * FIXED_POINT;\n\n      for (uint256 j = 0; j < trainingColIndices.length; j++) {\n        trainingData[i][j] = int256(analyticsData[i][trainingColIndices[j]]) * FIXED_POINT;\n      }\n\t\t}\n\n\t\tint256[] memory weights = fit(\n\t\t\ttrainingData,\n\t\t\tlabels,\n\t\t\tlearningRate,\n\t\t\titerations,\n\t\t\tbias\n\t\t);\n\n\t\tint256[] memory predictions = predict(testData, bias, weights);\n\n\t\treturn predictions;\n\t}\n\n  // Get linear regression for offchain data\n  function getLinearRegressionOffChainData(\n\t\tint256[][] memory analyticsData,\n\t\tint256[] memory labels,\n\t\tint256[][] memory testData,\n\t\tint256 learningRate,\n\t\tuint256 iterations,\n\t\tint256 bias\n\t) public pure returns (int256[] memory) {\n\t\t\n\n\t\tint256[] memory weights = fit(\n\t\t\tanalyticsData,\n\t\t\tlabels,\n\t\t\tlearningRate,\n\t\t\titerations,\n\t\t\tbias\n\t\t);\n\n\t\tint256[] memory predictions = predict(testData, bias, weights);\n\n\t\treturn predictions;\n\t}\n\n\n\t/**\n\t * Fits the linear regression model to the training data\n\t * @param X - The training features.\n\t * @param y - The training labels.\n\t */\n\tfunction fit(\n\t\tint256[][] memory X,\n\t\tint256[] memory y,\n\t\tint256 learningRate,\n\t\tuint256 iterations,\n\t\tint256 bias\n\t) public pure returns (int256[] memory) {\n\t\trequire(\n\t\t\tX.length == y.length,\n\t\t\t\"Feature and label arrays must have the same length.\"\n\t\t);\n\n\t\t// Initialize weights\n\t\tint256[] memory weights = new int256[](X[0].length);\n  \n\t\tfor (uint256 iter = 0; iter < iterations; iter++) {\n\t\t\tint256[] memory predictions = new int256[](X.length);\n\t\t\tint256[] memory dw = new int256[](X[0].length);\n\t\t\tint256 db = 0;\n\n\t\t\t// Compute predictions\n\t\t\tfor (uint256 i = 1; i < X.length; i++) {\n\t\t\t\tint256 linearModel = bias;\n\t\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\t\tlinearModel += (weights[j] * X[i][j]) / FIXED_POINT;\n\t\t\t\t}\n\t\t\t\tpredictions[i] = linearModel;\n\t\t\t}\n\n\t\t\t// Compute gradients\n\t\t\tfor (uint256 i = 1; i < X.length; i++) {\n\t\t\t\tint256 error = predictions[i] - y[i];\n\t\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\t\tdw[j] += (X[i][j] * error) / (int256(X.length) * FIXED_POINT);\n\t\t\t\t}\n        \n\t\t\t\tdb += error / int256(X.length);\n\t\t\t}\n\n\t\t\t// Update weights and bias\n\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\tweights[j] -= (learningRate * dw[j]) / FIXED_POINT;\n\t\t\t}\n\t\t\tbias -= (learningRate * db) / FIXED_POINT;\n\t\t}\n\n\t\treturn weights;\n\t}\n\n\t/**\n\t * Predicts the labels for the given input data\n\t * @param X - The input features.\n\t */\n\tfunction predict(\n\t\tint256[][] memory X,\n\t\tint256 bias,\n\t\tint256[] memory weights\n\t) public pure returns (int256[] memory) {\n\t\tuint256 m = X.length;\n\t\tint256[] memory predictions = new int256[](m);\n\n\t\tfor (uint256 i = 0; i < m; i++) {\n\t\t\tint256 linearModel = bias;\n\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\tlinearModel += (weights[j] * X[i][j]) / FIXED_POINT;\n\t\t\t}\n\t\t\tpredictions[i] = linearModel;\n\t\t}\n\n\t\treturn predictions;\n\t}\n}\n"
    },
    "contracts/LogisticRegression.sol": {
      "content": "//SPDX-License-Identifier: MIT\npragma solidity >=0.8.0 <0.9.0;\n\nimport \"./DataLayer.sol\";\n\ncontract LogisticRegression {\n\tDataLayer dataLayer;\n\n\tint256 constant FIXED_POINT = 1e9; // Scaling factor for fixed-point arithmetic\n\n\tconstructor(DataLayer _dataLayer) {\n\t\tdataLayer = _dataLayer;\n\t}\n\n  // Get linear regression for onchain schema data\n\tfunction getLogisticRegression(\n\t\tbytes32 schemaName,\n    uint256[] memory trainingColIndices,\n\t\tuint256 labelColIndex,\n    int256[][] memory testData,\n\t\tint256 learningRate,\n\t\tuint256 iterations,\n\t\tint256 bias\n\t) public view returns (int256[] memory) {\n\t\tuint256[][] memory analyticsData = dataLayer\n\t\t\t.getAnalyticsDataBySchemaName(schemaName);\n\n    int256[][] memory trainingData = new int256[][](analyticsData.length);\n\n\t\tint256[] memory labels = new int256[](analyticsData.length);\n\n\t\tfor (uint256 i = 1; i < analyticsData.length; i++) {\n      trainingData[i] = new int256[](trainingColIndices.length);\n\t\t\tlabels[i] = int256(analyticsData[i][labelColIndex]) * FIXED_POINT;\n\n      for (uint256 j = 0; j < trainingColIndices.length; j++) {\n        trainingData[i][j] = int256(analyticsData[i][trainingColIndices[j]]) * FIXED_POINT;\n      }\n\t\t}\n\n\t\tint256[] memory weights = fit(\n\t\t\ttrainingData,\n\t\t\tlabels,\n\t\t\tlearningRate,\n\t\t\titerations,\n\t\t\tbias\n\t\t);\n\n\t\tint256[] memory predictions = predict(testData, weights, bias);\n\n\t\treturn predictions;\n\t}\n\n\tfunction getLogisticRegressionOffChainData(\n\t\tint256[][] memory analyticsData,\n\t\tint256[] memory labels,\n\t\tint256[][] memory testData,\n\t\tint256 learningRate,\n\t\tuint256 iterations,\n\t\tint256 bias\n\t) public pure returns (int256[] memory) {\n\t\tint256[] memory weights = fit(\n\t\t\tanalyticsData,\n\t\t\tlabels,\n\t\t\tlearningRate,\n\t\t\titerations,\n\t\t\tbias\n\t\t);\n\n\t\tint256[] memory predictions = predict(testData, weights, bias);\n\n\t\treturn predictions;\n\t}\n\n\t/**\n\t * Fits the logistic regression model to the training data\n\t * @param X - The training features.\n\t * @param y - The training labels.\n\t */\n\tfunction fit(\n\t\tint256[][] memory X,\n\t\tint256[] memory y,\n\t\tint256 learningRate,\n\t\tuint256 iterations,\n\t\tint256 bias\n\t) public pure returns (int256[] memory) {\n\t\trequire(\n\t\t\tX.length == y.length,\n\t\t\t\"Feature and label arrays must have the same length.\"\n\t\t);\n\n\t\t// Initialize weights\n\t\tint256[] memory weights = new int256[](X[0].length);\n\n\t\tfor (uint256 iter = 0; iter < iterations; iter++) {\n\t\t\tint256[] memory linearModel = new int256[](X.length);\n\t\t\tint256[] memory predictions = new int256[](X.length);\n\t\t\tint256[] memory dw = new int256[](X[0].length);\n\t\t\tint256 db = 0;\n\n\t\t\t// Compute linear model and predictions\n\t\t\tfor (uint256 i = 1; i < X.length; i++) {\n\t\t\t\tlinearModel[i] = bias;\n\t\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\t\tlinearModel[i] += (weights[j] * X[i][j]) / FIXED_POINT;\n\t\t\t\t}\n\t\t\t\tpredictions[i] = sigmoid(linearModel[i]);\n\t\t\t}\n\n\t\t\t// Compute gradients\n\t\t\tfor (uint256 i = 1; i < X.length; i++) {\n\t\t\t\tint256 error = predictions[i] - y[i];\n\t\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\t\tdw[j] += (X[i][j] * error) / FIXED_POINT;\n\t\t\t\t}\n\t\t\t\tdb += error;\n\t\t\t}\n\n\t\t\t// Update weights and bias\n\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\tweights[j] -= (learningRate * dw[j]) / (int256(X.length) * FIXED_POINT);\n\t\t\t}\n\t\t\tbias -= (learningRate * db) / (int256(X.length) * FIXED_POINT);\n\t\t}\n\n\t\treturn weights;\n\t}\n\n\t/**\n\t * Predicts the labels for the given input data\n\t * @param X - The input features.\n\t */\n\tfunction predict(\n\t\tint256[][] memory X,\n\t\tint256[] memory weights,\n\t\tint256 bias\n\t) public pure returns (int256[] memory) {\n\t\tuint256 m = X.length;\n\t\tint256[] memory predictions = new int256[](m);\n\n\t\tfor (uint256 i = 0; i < m; i++) {\n\t\t\tint256 linearModel = bias;\n\t\t\tfor (uint256 j = 0; j < X[0].length; j++) {\n\t\t\t\tlinearModel += (weights[j] * X[i][j]) / FIXED_POINT;\n\t\t\t}\n\t\t\tpredictions[i] = sigmoid(linearModel) > (FIXED_POINT / int256(2))\n\t\t\t\t? int256(1 * FIXED_POINT)\n\t\t\t\t: int256(0);\n\t\t}\n\n\t\treturn predictions;\n\t}\n\n\t/**\n\t * Sigmoid function\n\t * @param z - The input value.\n\t */\n\tfunction sigmoid(int256 z) internal pure returns (int256) {\n\t\tint256 expValue = exp(z);\n\t\treturn (expValue * FIXED_POINT) / (FIXED_POINT + expValue);\n\t}\n\n\t/**\n\t * Exponential function approximation\n\t * @param x - The input value.\n\t */\n\tfunction exp(int256 x) internal pure returns (int256) {\n\t\tint256 sum = FIXED_POINT;\n\t\tint256 term = FIXED_POINT;\n\t\tfor (int256 i = 1; i < 30; i++) {\n\t\t\tterm = (term * x) / int256(i * FIXED_POINT);\n\t\t\tsum += term;\n\t\t}\n\t\treturn sum;\n\t}\n}\n"
    }
  },
  "settings": {
    "optimizer": {
      "enabled": true,
      "runs": 200
    },
    "viaIR": true,
    "outputSelection": {
      "*": {
        "*": [
          "abi",
          "evm.bytecode",
          "evm.deployedBytecode",
          "evm.methodIdentifiers",
          "metadata",
          "devdoc",
          "userdoc",
          "storageLayout",
          "evm.gasEstimates"
        ],
        "": [
          "ast"
        ]
      }
    },
    "metadata": {
      "useLiteralContent": true
    }
  }
}